# Data Engineer Nanodegree - Project 1: Data model with PostgreSQL

- [Data Engineer Nanodegree - Project 1: Data model with PostgreSQL](#data-engineer-nanodegree---project-1-data-model-with-postgresql)
  - [Summary](#summary)
  - [Dataset](#dataset)
  - [Schema](#schema)
  - [How to run](#how-to-run)
    - [1. PostgreSQL](#1-postgresql)
    - [2. Requirements](#2-requirements)
    - [3. Create tables](#3-create-tables)
    - [4. ETL](#4-etl)
    - [5. Test and inspect](#5-test-and-inspect)
  - [Purpose of the database](#purpose-of-the-database)
## Summary

A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

## Dataset

The project is based on two dataset:
- **Song dataset**: it is a subset of real data from the [Million Song Dataset](https://labrosa.ee.columbia.edu/millionsong/). Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. For example, here are filepaths to two files in this dataset.

   ```
    song_data/A/B/C/TRABCEI128F424C983.json
    song_data/A/A/B/TRAABJL12903CDCF1A.json
   ```
    And below is an example of what a single song file, TRAABJL12903CDCF1A.json, looks like.

    ```json
    {
        "num_songs": 1,
        "artist_id": "ARJIE2Y1187B994AB7",
        "artist_latitude": null,
        "artist_longitude": null,
        "artist_location": "",
        "artist_name": "Line Renaud",
        "song_id": "SOUPIRU12A6D4FA1E1",
        "title": "Der Kleine Dompfaff",
        "duration": 152.92036,
        "year": 0
    }
    ```

- **Log Dataset**: it consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

    The log files in the dataset you'll be working with are partitioned by year and month. For example, here are filepaths to two files in this dataset.

    ```
    log_data/2018/11/2018-11-12-events.json
    log_data/2018/11/2018-11-13-events.json
    ```

## Schema
In order to analyze and query the data, Sparkify wants to create an OLAP database with PostgreSQL. After the etl process, the star schema resulting in the database will be the following:

**Songoplays table** (Fact table)
| Column name | Type      | Properties        |
| ----------- | --------- | ----------------- |
| songplay_id | BIGSERIAL | PK, AUTOINCREMENT |
| start_time  | timestamp |                   |
| user_id     | int       |                   |
| level       | varchar   |                   |
| song_id     | varchar   |                   |
| artist_id   | varchar   |                   |
| session_id  | int       |                   |
| location    | varchar   |                   |
| user_agent  | varchar   |                   |

**Songs**
| Column name | Type    | Properties |
| ----------- | ------- | ---------- |
| song_id     | varchar | PK         |
| title       | varchar |            |
| artist_id   | varchar |            |
| year        | int     |            |
| duration    | numeric |            |

**Artists**
| Column name | Type    | Properties |
| ----------- | ------- | ---------- |
| artist_id   | varchar | PK         |
| name        | varchar |            |
| location    | varchar |            |
| latitude    | numeric |            |
| longitude   | numeric |            |

**Users**
| Column name | Type    | Properties |
| ----------- | ------- | ---------- |
| user_id     | varchar | PK         |
| firsname    | varchar |            |
| lastname    | varchar |            |
| gender      | char    |            |
| level       | varchar |            |

**Time**
| Column name | Type      | Properties |
| ----------- | --------- | ---------- |
| start_time  | timestamp | PK         |
| hour        | int       |            |
| day         | int       |            |
| week        | int       |            |
| month       | int       |            |
| year        | int       |            |
| weekday     | int       |            |


## How to run

### 1. PostgreSQL
In order to run this project you must have a PostgreSQL database configured in your localhost with:
- a user "student"
- a db calles "sparkify"

If you don't have it available, you can use Docker to easly create and configure it. Simply execute these commands from the root of the project:
```bash
docker run --name pg -e POSTGRES_PASSWORD=pass -p 5432:5432 -d postgres
docker cp init_postgres.sql pg:/init.sql
docker exec -it pg psql -U postgres -f /init.sql
```
### 2. Requirements
Be sure to have all requirements satisfied executing:
```
pip install -r requirements.txt
```

The `requirements-dev.txt` contains requirements for development (like pre-commit, black, isort ...) but they aren't necessary for running the project.

### 3. Create tables
Then, create tables using the `create_tables.py` Python script.

### 4. ETL
Now, you are ready to run the etl process executing the `etl.py` script.

### 5. Test and inspect

You can inspect the results of the etl process with the `test` notebook:
```
jupyter notebook
```
This will open the Jupiter interface. Open the `test.ipynb` notebook and start querying the db.


## Purpose of the database

Sparkify wants to create this database to analyze and get insight from the data collected by their app. In fact, the app collects a lot of user actions, but the proble is: how to process all these data and how to get infromations from this logs? Creating an OLAP db like this, Sparkify can query the database, aggregate data and understand what songs users are listening.

Looking at the database, some possible and useful queries that Sparkify's team can execute are:
- Trending songs in a certain location
    ```SQL
    SELECT s.song_id, title, count(*) as plays
    FROM songplays AS sp JOIN songs AS s ON sp.song_id = s.song_id
    WHERE location = 'Chicago-Naperville-Elgin, IL-IN-WI'
    GROUP BY s.song_id
    ORDER BY plays DESC
    ```
- Trending artists in a certain location (similar to the previous query)
- How many songs are listened per session by user with free and paid level
    ```sql
    SELECT level, avg(songs)
    FROM (
            SELECT session_id, level, count(*) AS songs
            FROM songplays
            GROUP BY session_id, level
        ) AS t1
    GROUP BY level
    ```
- Top 20 songs for specific a year
  ```sql
  SELECT sp.song_id, title, count(*) AS plays
  FROM songplays AS sp JOIN songs AS s ON sp.song_id = s.song_id WHERE year = 2019
  GROUP BY sp.song_id, title
  ORDER BY plays DESC
  LIMIT 20

  ```

A lot of other queries can be executed to analyze the populatiry of songs and artists, also using geographic information, or analyze user behavior at a specific period of the day/month/week.
